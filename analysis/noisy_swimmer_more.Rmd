---
title: Yet more NMF analyses of the (noisy) swimmer data
author: Jason Willwerscheid and Peter Carbonetto
output:
  workflowr::wflow_html:
    toc: no
    theme: readable
    highlight: textmate
    lib_dir: site_libs
    self_contained: no
---

This workflowr page contains some additional explorations of NMF
methods—including the EBNMF methods implemented in flashier---for
learning parts from the "noisy" swimmer data.

```{r knitr-opts, include=FALSE}
knitr::opts_chunk$set(comment = "#",collapse = TRUE,results = "hold",
                      fig.align = "center",dpi = 120)
```

First, load the packages and some custom functions needed for the
analyses below.

```{r load-pkgs, message=FALSE}
library(R.matlab)
library(tibble)
library(dplyr)
library(tidyr)
library(ggplot2)
library(cowplot)
library(ebnm)
library(flashier)
source("code/swimmer_functions.R")
```

Initialize the sequence of pseudorandom numbers.

```{r set-seed}
set.seed(1)
```

Load the swimmer data set and convert the pixels to binary.

```{r load-swimmer}
Y <- readMat("data/swimmer.mat")$Y
Y <- apply(Y,3,as.vector)
Y <- Y - 1
Y[Y > 0] <- 1
```

Add some noise to the images.

```{r add-noise, fig.height=2, fig.width=7}
Y <- generate_noisy_swimmer_data(Y,0.05)
writeMat("noisy_swimmer.mat",Y = Y)
plot_images(Y[,1:16],nrow = 2,ncol = 8)
```

This is the decomposition produced by "vanilla NMF" with 16 factors—by
"vanilla", we mean NMF without any penalties on the parameters. See
[noisy_swimmer.m][noisy_swimmer_matlab] for details.

```{r vanilla-nmf, fig.height=2, fig.width=7}
nmf <- readMat("matlab/noisy_swimmer_nmf.mat")
plot_images(nmf$W,nrow = 3,ncol = 8)
```

This decomposition has trouble distinguishing the torso from the
limbs, and doesn't always split the limbs into separate factors. Also,
many of the limbs are quite noisy. Perhaps encouraging the parts to be
more sparse would address these issues with this. In this second
attempt (also implemented in [noisy_swimmer.m][noisy_swimmer_matlab]),
we forced the average sparsity of the 17 factors to be at least 0.8:

```{r sparse-nmf, fig.height=3, fig.width=7}
sparse_nmf <- readMat("matlab/noisy_swimmer_nmf_sW=0.8.mat")
plot_images(sparse_nmf$W,nrow = 3,ncol = 8)
```

Although not perfect—the factors have captured a lot of background
noise, and the torso is still included with some of the limbs—this
sparse NMF decomposition is nonetheless a clear improvement over the
vanilla NMF result.

Let's now see what happens when we force the sparsity to be even
higher (0.9):

```{r more-sparse-nmf, fig.height=3, fig.width=7}
more_sparse_nmf <- readMat("matlab/noisy_swimmer_nmf_sW=0.9.mat")
plot_images(more_sparse_nmf$W,nrow = 3,ncol = 8)
```

The sparser decomposition removes a lot of the background noise in the
factors, but also introduces some new problems: for example, some of
the factors are reduced to a single pixel or just a few pixels, and
other factors now include multiple limbs, which is not right.

To double-check, here are the average sparsity values from each of
these NMF decompositions:

```{r compare-sparsity}
mean(nmf$sp)
mean(sparse_nmf$sp)
mean(more_sparse_nmf$sp)
```

Let's now compare the NMF estimates to a decomposition-by-parts
obtained by running flashier with sparse, non-negative priors,
`ebnm_point_exponential`. Remarkably, running flash with the
point-exponential prior gets the right result, automatically splitting
the torso and limb positions correctly into 17 factors (plus one more
factor that ends up capturing the noise). Also, flashier *adapts* the
priors to capture the fact that the factors are very sparse:

```{r flash, results="hide", fig.height=3, fig.width=7}
fit1 <- flash(Y,ebnm_fn = ebnm_point_exponential,greedy_Kmax = 18,
              backfit = TRUE,var_type = 0)
plot_images(ldf(fit1)$L,nrow = 3,ncol = 8)
```

(Note that we needed to tell flashier we wanted at most 18 factors
otherwise flashier would give us more than 18.)

Let's now look at this remarkable result more closely.

By default, flashier initializes the factors in a "greedy" way, which
is different from the more typical random initialization in NMF.
Indeed, [SparseNMF.m][sparsenmf] is initialized at random by
default. The greedy initialization appears as follows:

```{r flash-greedy, results="hide", fig.height=3, fig.width=7}
fit_greedyinit <- flash(Y,ebnm_fn = ebnm_point_exponential,
                        greedy_Kmax = 18,backfit = FALSE,
						var_type = 0)
plot_images(ldf(fit_greedyinit)$L,nrow = 3,ncol = 8)
```

The greedy initialization appears particularly well suited for the
swimmer data set (backfitting only needs to clean up the first
factor). And this seems due in large part to the "greediness" of the
approach rather than to any sparsity-inducing properties of the
priors. Indeed, if we simply use flashier's greedy initialization
function (alternating least-squares) without doing any optimization on
the initialized factors, we get similar results:

```{r flash-greedy-2, fig.height=3, fig.width=7}
k <- 18
fl2 <- flash_init(Y)
for (i in 1:k) {
  next_f <- flash_greedy_init_default(flash_fit(fl2),seed = i,
                                      sign_constraints = c(1,1))
  next_f <- lapply(next_f,as.matrix,ncol = 1)
  fl2    <- flash_factors_init(fl2,next_f)
}
L  <- ldf(fl2)$L
ks <- which(apply(is.finite(L),2,all))
L  <- L[,ks]
write.table(round(L,digits = 6),"flash_greedy_init_noisy_L.txt",
            row.names = FALSE,col.names = FALSE)
write.table(round(ldf(fl2)$F[,ks],digits = 6),"flash_greedy_init_noisy_F.txt",
            row.names = FALSE,col.names = FALSE)
plot_images(L,nrow = 3,ncol = 8)
```

And, indeed, sparse NMF initialized to this greedy initialization
finds a pretty good solution (see
[noisy_swimmer.m][noisy_swimmer_matlab] for details):

```{r, fig.height=3, fig.width=7}
nmf_greedy_init <- readMat("matlab/noisy_swimmer_nmf_greedy_init_sW=0.9.mat")
plot_images(nmf_greedy_init$W,nrow = 3,ncol = 8)
```

[noisy_swimmer_matlab]: https://github.com/willwerscheid/ebnmf-paper/blob/master/matlab/noisy_swimmer.m
[sparsenmf]: https://github.com/willwerscheid/ebnmf-paper/blob/master/matlab/sparseNMF.m
