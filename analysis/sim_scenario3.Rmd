---
title: NMF analyses of simulated data, Scenario 3
author: Jason Willwerscheid and Peter Carbonetto
output:
  workflowr::wflow_html:
    toc: no
    theme: readable
    highlight: textmate
    lib_dir: site_libs
    self_contained: no
---

```{r knitr-opts, include=FALSE}
knitr::opts_chunk$set(comment = "#",collapse = TRUE,results = "hold",
                      fig.align = "center",dpi = 120)
```

```{r load-pkgs, message=FALSE}
library(R.matlab)
library(tibble)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(cowplot)
library(ebnm)
library(flashier)
library(fastTopics)
source("code/swimmer_functions.R")
```

We use three different fitting methods:

1. "NMF": Uses package `NNLM`. As is common practice, we do 10 trials and choose the fit with the lowest error.

2. "NMF-EBNMF": EBNMF using an NMF initialization. We test `var_type = 0` and `var_type2`; we refer to these submethods as "NMF-EBNMF0" and "NMF-EBNMF2".

3. "EBNMF": An EBNMF fit produced by alternatively adding one "greedy" factor and running 10 backfitting iterations (so, we backfit after *each* new factor is added). After no new factor can be added, we perform a full backfit. We again test `var_type = 0` and `var_type2`, giving "EBNMF0" and "EBNMF2".

The fitting functions appear as follows:

```{r}
run_nmf <- function(Y, k, ntrials = 10) {
  cat("Running NMF")
  t <- system.time({
    best_mse <- Inf
    for (i in 1:ntrials) {
      cat(".")
      set.seed(i)
      next_res <- NNLM::nnmf(Y, k = k, verbose = 0)
      if (min(next_res$mse) < best_mse) {
        best_mse <- min(next_res$mse)
        best_res <- next_res
      }
    }
  })
  cat("\n")

  return(list(t = t, fit = best_res))
}

run_ebnmf_from_nmf <- function(Y, nmf_res, var_type, maxiter = 2000) {
  cat("Running EBNMF from NMF:\n")
  t <- system.time({
    fl <- flash_init(Y, var_type = var_type) |>
      flash_factors_init(list(nmf_res$W, t(nmf_res$H)), ebnm_fn = ebnm_point_exponential) |>
      flash_backfit(maxiter = maxiter, verbose = 0) |>
      flash_nullcheck(verbose = 0)
  })
  
  return(list(t = t, fit = fl))
}

run_alternating_gb <- function(Y, Kmax, var_type = 2) {
  cat("Running alternating EBNMF")
  t <- system.time({
    fl <- flash_init(Y, var_type = var_type) |>
      flash_set_verbose(0)
    keep_going <- TRUE
    while(keep_going) {
      cat(".")
      current_n <- fl$n_factors
      fl <- fl |>
        flash_greedy(ebnm_fn = ebnm_point_exponential) |>
        flash_backfit(maxiter = 10)
      if (fl$n_factors == current_n | fl$n_factors == Kmax) {
        keep_going <- FALSE
      }
    }
    cat("\n")
    fl <- fl |>
      flash_backfit(maxiter = 2000, verbose = 0) |>
      flash_nullcheck(verbose = 0)
  })
  
  return(list(t = t, fit = fl))
}
```

In this analysis we consider the "hierarchical" scenario. Here there are seven topics: a "root" topic shared by four populations, two "branch" topics shared by two populations each, and four "leaf" topics that are unique to one population each. We also add 7 populations consisting of "anchor documents." We fix the size of the hierarchically-related populations at 250 and vary the number of anchor documents from 2 to 100 per population. The `L` matrix codes population memberships. The factors `F` and the log1p link function are as in the previous analysis.

```{r}
sim_data <- function(ns, p, gamma_shape, gamma_scale, n_anchor_words = 10, link = "log1p") {
  k <- 7
  
  # Loadings (document-topics):
  L <- matrix(0, nrow = sum(ns), ncol = k)
  L[, 7] <- c(rep(1/3, sum(ns[1:4])), rep(1, ns[5]), rep(0, sum(ns[6:11]))) # root
  L[, 5] <- c(rep(1/3, sum(ns[1:2])), rep(0, sum(ns[3:5])), rep(1, ns[6]), rep(0, sum(ns[7:11]))) # branch 1
  L[, 6] <- c(rep(0, sum(ns[1:2])), rep(1/3, sum(ns[3:4])), rep(0, sum(ns[5:6])), rep(1, ns[7]), rep(0, sum(ns[8:11]))) # branch 2
  L[, 1] <- c(rep(1/3, ns[1]), rep(0, sum(ns[2:7])), rep(1, ns[8]), rep(0, sum(ns[9:11]))) # leaf 1
  L[, 2] <- c(rep(0, ns[1]), rep(1/3, ns[2]), rep(0, sum(ns[3:8])), rep(1, ns[9]), rep(0, sum(ns[10:11]))) # leaf 2
  L[, 3] <- c(rep(0, sum(ns[1:2])), rep(1/3, ns[3]), rep(0, sum(ns[4:9])), rep(1, ns[10]), rep(0, ns[11])) # leaf 3
  L[, 4] <- c(rep(0, sum(ns[1:3])), rep(1/3, ns[4]), rep(0, sum(ns[5:10])), rep(1, ns[11])) # leaf 4

  set.seed(1)
  F <- matrix(rgamma(p * k, shape = gamma_shape, scale = gamma_scale), nrow = p, ncol = k)
  
  # Anchor words
  n_anchor_words <- 10
  for (i in 1:k) {
    F[((i - 1) * n_anchor_words + 1):(i * n_anchor_words), setdiff(1:k, i)] <- 0
  }
  
  mu <- L %*% t(F)
  if (link == "identity") {
    Y <- matrix(rpois(sum(ns) * p, mu), nrow = sum(ns), ncol = p)
  } else if (link == "log1p") {
    Y <- matrix(log1p(rpois(sum(ns) * p, expm1(mu))), nrow = sum(ns), ncol = p)
  }
  
  # Make sure there aren't any all-zero columns:
  F <- F[apply(Y, 2, sum) > 0, ]
  Y <- Y[, apply(Y, 2, sum) > 0]
  
  rownames(Y) <- paste0("sample", 1:nrow(Y))
  colnames(Y) <- paste0("feature", 1:ncol(Y))

  return(list(Y = Y, L = L, F = F))
}
```

The metrics are as in the previous analysis.

```{r}
calc_metrics <- function(res, sim_dat) {
  fit <- res$fit
  if (inherits(fit, "flash")) {
    LDF <- ldf(fit, type = "f")
    LL <- t(t(LDF$L) * LDF$D)
    FF <- t(t(LDF$F) * LDF$D)
  } else {
    Wscale <- sqrt(apply(fit$W, 2, function(x) sum(x^2)))
    Hscale <- sqrt(apply(fit$H, 1, function(x) sum(x^2)))
    D <- Wscale * Hscale
    LL <- t(t(fit$W) / sqrt(Wscale) * sqrt(Hscale))
    FF <- t(fit$H / sqrt(Hscale) * sqrt(Wscale))
  }
  
  # Metrics for components 1-7 are correlations:
  LL_cors <- FF_cors <- rep(NA, ncol(sim_dat$L))
  used_cols <- numeric(0)
  LL_cormat <- cor(sim_dat$L, LL)
  FF_cormat <- cor(sim_dat$F, FF)
  for (i in 1:min(ncol(sim_dat$L), ncol(LL))) {
    rowmax <- which.max(apply(abs(LL_cormat), 1, max))
    colmax <- which.max(apply(abs(LL_cormat), 2, max))
    LL_cors[rowmax] <- LL_cormat[rowmax, colmax]
    FF_cors[rowmax] <- FF_cormat[rowmax, colmax]
    LL_cormat[, colmax] <- 0
    LL_cormat[rowmax, ] <- 0
    used_cols <- c(used_cols, colmax)
  }
  
  # Metrics for 8-12 are the scales of these (redundant/noisy) components:
  L_scales <- apply(LL, 2, function(x) sum(x^2))
  L_scales <- L_scales / sum(L_scales)
  unmatched_scales <- L_scales[-used_cols]
  unmatched_scales <- sort(unmatched_scales, decreasing = TRUE)
  unmatched_scales <- c(unmatched_scales, rep(NA, 5 - length(unmatched_scales)))

  all_metrics <- c(LL_cors, FF_cors, unmatched_scales)
  names(all_metrics) <- c(
    paste0("LLcor", 1:7),
    paste0("FFcor", 1:7),
    paste0("Scale", 8:12)
  ) 
  
  return(all_metrics)
}

next_tib <- function(shape, ns, method, Kmax, res, sim_dat) {
  metrics <- calc_metrics(res, sim_dat)
  return(tibble(
    method = method,
    Kmax = Kmax,
    n_anchor_docs = ns[8],
    shape = shape,
    metric_type = c("t_elapsed", names(metrics)),
    metric_val = c(res$t[3], metrics)
  ))
}
```

Run simulations. We consider results for when the true `K = 7` is given in advance as well as for when `K` is overspecified (here, `Kmax = 12`):

```{r echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE, results='hide'}
all_res <- tibble()

set.seed(1)
for (n_anchor_docs in c(2, 5, 10, 25, 50, 100)) {
  for (shape in c(0.25, 0.33, 0.5, 0.75, 1, 2, 4)) {
    cat("ANCHOR DOCS: ", n_anchor_docs, "SHAPE: ", shape, "\n")
    
    gamma_mean <- 1
    scale <- gamma_mean / shape 
    
    ns <- c(rep(250, 4), rep(n_anchor_docs, 7))
    p <- 500
    
    sim_dat <- sim_data(ns, p, gamma_shape = shape, gamma_scale = scale)
    Y <- sim_dat$Y
    
    nmf_res_k7 <- run_nmf(Y, k = 7)
    all_res <- all_res |> 
      bind_rows(next_tib(shape, ns, "NMF", 7, nmf_res_k7, sim_dat))
    
    all_res <- all_res |> 
      bind_rows(next_tib(shape, ns, "NMF-EBNMF0", 7, run_ebnmf_from_nmf(Y, nmf_res_k7$fit, var_type = 0), sim_dat))
    
    all_res <- all_res |> 
      bind_rows(next_tib(shape, ns, "NMF-EBNMF2", 7, run_ebnmf_from_nmf(Y, nmf_res_k7$fit, var_type = 2), sim_dat))

    all_res <- all_res |> 
      bind_rows(next_tib(shape, ns, "EBNMF0", 7, run_alternating_gb(Y, Kmax = 7, var_type = 0), sim_dat))

    all_res <- all_res |> 
      bind_rows(next_tib(shape, ns, "EBNMF2", 7, run_alternating_gb(Y, Kmax = 7, var_type = 2), sim_dat))
    
    nmf_res_k12 <- run_nmf(Y, k = 12)
    all_res <- all_res |> 
      bind_rows(next_tib(shape, ns, "NMF", 12, nmf_res_k12, sim_dat))
    
    all_res <- all_res |> 
      bind_rows(next_tib(shape, ns, "NMF-EBNMF0", 12, run_ebnmf_from_nmf(Y, nmf_res_k12$fit, var_type = 0), sim_dat))
    
    all_res <- all_res |> 
      bind_rows(next_tib(shape, ns, "NMF-EBNMF2", 12, run_ebnmf_from_nmf(Y, nmf_res_k12$fit, var_type = 2), sim_dat))

    all_res <- all_res |> 
      bind_rows(next_tib(shape, ns, "EBNMF0", 12, run_alternating_gb(Y, Kmax = 12, var_type = 0), sim_dat))

    all_res <- all_res |> 
      bind_rows(next_tib(shape, ns, "EBNMF2", 12, run_alternating_gb(Y, Kmax = 12, var_type = 2), sim_dat))
  }
}
```

## Results, Kmax = 7

Correlations for `L`. Each row gives correlations for one true component (one "population"), with rows arranged according to the abundance of the population (in descending order). Individual tiles correspond to individual simulations (a single combination of gamma shape and shared population size):

```{r}
plot_df <- all_res |> filter(Kmax == 7, str_starts(metric_type, "LLcor")) |>
  mutate(n_anchor_docs = factor(n_anchor_docs), 
         shape = factor(shape),
         method = factor(method, levels = c("NMF", "NMF-EBNMF2", "NMF-EBNMF0", "EBNMF2", "EBNMF0"))) |>
  mutate(metric_val = pmin(metric_val, 0.9999))
ggplot(plot_df, aes(x = n_anchor_docs, y = shape, fill = metric_val)) +
  geom_tile() +
  scale_fill_gradient(low = "red", high = "blue", na.value = "red", transform = "logit") +
  facet_grid(rows = vars(metric_type), cols = vars(method), scales = "free_x") +
  labs(x = "Size of shared populations", y = "Shape of gamma prior on factors", fill = "Cor. w/ true L") +
  theme(axis.text.x = element_text(angle = 45))
```

Correlations for `F`:

```{r}
plot_df <- all_res |> filter(Kmax == 7, str_starts(metric_type, "FFcor")) |>
  mutate(n_anchor_docs = factor(n_anchor_docs), 
         shape = factor(shape),
         method = factor(method, levels = c("NMF", "NMF-EBNMF2", "NMF-EBNMF0", "EBNMF2", "EBNMF0"))) |>
  mutate(metric_val = pmin(metric_val, 0.9999))
ggplot(plot_df, aes(x = n_anchor_docs, y = shape, fill = metric_val)) +
  geom_tile() +
  scale_fill_gradient(low = "red", high = "blue", na.value = "red", transform = "logit") +
  facet_grid(rows = vars(metric_type), cols = vars(method), scales = "free_x") +
  labs(x = "Number of anchor documents", y = "Shape of gamma prior on factors", fill = "Cor. w/ true F") +
  theme(axis.text.x = element_text(angle = 45))
```

## Results, Kmax = 12

Correlations for `L`:

```{r}
plot_df <- all_res |> filter(Kmax == 12, str_starts(metric_type, "LLcor")) |>
  mutate(n_anchor_docs = factor(n_anchor_docs), 
         shape = factor(shape),
         method = factor(method, levels = c("NMF", "NMF-EBNMF2", "NMF-EBNMF0", "EBNMF2", "EBNMF0"))) |>
  mutate(metric_val = pmin(metric_val, 0.9999))
ggplot(plot_df, aes(x = n_anchor_docs, y = shape, fill = metric_val)) +
  geom_tile() +
  scale_fill_gradient(low = "red", high = "blue", na.value = "red", transform = "logit") +
  facet_grid(rows = vars(metric_type), cols = vars(method), scales = "free_x") +
  labs(x = "Number of anchor documents", y = "Shape of gamma prior on factors", fill = "Cor. w/ true L") +
  theme(axis.text.x = element_text(angle = 45))
```

Correlations for `F`:

```{r}
plot_df <- all_res |> filter(Kmax == 12, str_starts(metric_type, "FFcor")) |>
  mutate(n_anchor_docs = factor(n_anchor_docs), 
         shape = factor(shape),
         method = factor(method, levels = c("NMF", "NMF-EBNMF2", "NMF-EBNMF0", "EBNMF2", "EBNMF0"))) |>
  mutate(metric_val = pmin(metric_val, 0.9999))
ggplot(plot_df, aes(x = n_anchor_docs, y = shape, fill = metric_val)) +
  geom_tile() +
  scale_fill_gradient(low = "red", high = "blue", na.value = "red", transform = "logit") +
  facet_grid(rows = vars(metric_type), cols = vars(method), scales = "free_x") +
  labs(x = "Number of anchor documents", y = "Shape of gamma prior on factors", fill = "Cor. w/ true F") +
  theme(axis.text.x = element_text(angle = 45))
```

Scale of redundant/noisy factors. If any exist, they are arranged in descending order, with the largest redundant/noisy factor appearing in the top row:

```{r}
plot_df <- all_res |> filter(Kmax == 12, str_starts(metric_type, "Scale")) |>
  mutate(n_anchor_docs = factor(n_anchor_docs, ), 
         shape = factor(shape),
         method = factor(method, levels = c("NMF", "NMF-EBNMF2", "NMF-EBNMF0", "EBNMF2", "EBNMF0"))) |>
  mutate(metric_type = factor(metric_type, levels = paste("Scale", 8:12)))
ggplot(plot_df, aes(x = n_anchor_docs, y = shape, fill = metric_val)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "purple", na.value = "white") +
  facet_grid(rows = vars(metric_type), cols = vars(method), scales = "free_x") +
  labs(x = "Number of anchor documents", y = "Shape of gamma prior on factors", fill = "Scale") +
  theme(axis.text.x = element_text(angle = 45))
```

## Time elapsed

```{r}
plot_df <- all_res |> filter(str_starts(metric_type, "t_elapsed")) |>
  mutate(n_anchor_docs = factor(n_anchor_docs), 
         shape = factor(shape),
         Kmax = factor(Kmax),
         method = factor(method, levels = c("NMF", "NMF-EBNMF2", "NMF-EBNMF0", "EBNMF2", "EBNMF0"))) 
ggplot(plot_df, aes(x = n_anchor_docs, y = shape, fill = metric_val)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "darkgreen", na.value = "black", transform = "log10") +
  facet_grid(rows = vars(Kmax), cols = vars(method), scales = "free_x") +
  labs(x = "Number of anchor documents", y = "Shape of gamma prior on factors", fill = "Time elapsed (s)") +
  theme(axis.text.x = element_text(angle = 45))
```
